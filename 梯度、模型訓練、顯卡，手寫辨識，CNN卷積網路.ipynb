##梯度下降法
import numpy as np
import matplotlib.pyplot as plt
# 目標函數:y=x^2
def func(x): return np.square(x)
# 目標函數一階導數:dy/dx=2*x
def dfunc(x): return 2 * x
def GD(x_start, df, epochs, lr):    
    """  梯度下降法。給定起始點與目標函數的一階導函數，求在epochs次反覆運算中x的更新值
        :param x_start: x的起始點    
        :param df: 目標函數的一階導函數    
        :param epochs: 反覆運算週期    
        :param lr: 學習率    
        :return: x在每次反覆運算後的位置（包括起始點），長度為epochs+1    
     """    
    xs = np.zeros(epochs+1)    
    x = x_start    
    xs[0] = x    
    for i in range(epochs):         
        dx = df(x)        
        # v表示x要改變的幅度        
        v = - dx * lr        
        x += v        
        xs[i+1] = x    
    return xs
# Main
# 起始權重
x_start = 5    
# 執行週期數
epochs = 10 
# 學習率   
lr = 0.2   
# 梯度下降法 
x = GD(x_start, dfunc, epochs, lr=lr) 
print (x)
# 輸出：[-5.     -2.     -0.8    -0.32   -0.128  -0.0512]
color = 'r'    
#plt.plot(line_x, line_y, c='b')    
from numpy import arange
t = arange(-6.0, 6.0, 0.01)
plt.plot(t, func(t), c='b')
plt.plot(x, func(x), c=color, label='lr={}'.format(lr))    
plt.scatter(x, func(x), c=color, )    
plt.legend()
plt.show()
     

##模型訓練
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout

#模型建立 
model = Sequential()
model.add(Dense(512, activation='relu', input_dim=784)) #第一層 訓練512個神經元
model.add(Dropout(0.2)) #第二層 丟掉0.2個神經元
model.add(Dense(10, activation='softmax')) #第三層 取出10個神經元
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
 
import numpy as np
data = np.random.random((1000, 784)) 
labels = np.random.randint(10, size=(1000, 10))
 
#模型訓練
model.fit(data, labels, epochs=10, batch_size=32)
#模型預測
score=model.evaluate(data, labels)
print(score[1])
     

##顯示卡
!nvidia-smi
     

##手寫辨識
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten
model=Sequential() #模型建立
model.add(Flatten())
model.add(Dense(100, activation='relu', input_dim=784)) #訓練100個神經元
model.add(Dense(10, activation='sigmoid')) #取10個神經元
model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])   #模型編譯  
     

mnist=keras.datasets.mnist
(train_data, train_label), (test_data, test_label) = mnist.load_data()
     

print(type(train_data))
print(train_data.shape)
print(type(train_label))
print(train_label.shape)
print(test_data.shape)
print(test_label.shape)
     

print(train_label[0])
print(train_data[0])
     

import matplotlib.pyplot as plt
plt.imshow(train_data[0], cmap='binary')
plt.show()
     

model.fit(train_data,train_label,epochs=20,batch_size=512) #模型尋練
     

score=model.evaluate(test_data, test_label)
print(score[1])
     

#CNN 卷積網路
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
model=Sequential()
model.add(Conv2D(filters=16, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2))) #1/4
#model.add(Conv2D(filters=36, kernel_size=(5, 5), activation='relu'))
#model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(10, activation='softmax'))
model.summary()
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
     

mnist=keras.datasets.mnist
(train_data, train_label), (test_data, test_label) = mnist.load_data()
test_label_original=test_label #for crosstab
train_label = keras.utils.to_categorical(train_label)
test_label = keras.utils.to_categorical(test_label)
     

train_history=model.fit(train_data,train_label,epochs=10,batch_size=512)

     

score=model.evaluate(test_data, test_label)
print(score[1])
     

#繪製正確性與損失立歷史圖
import matplotlib.pyplot as plt
import numpy as np

def show_train_history(train_history, train, validation):
    plt.plot(train_history.history[train])
    plt.plot(train_history.history[validation])
    plt.title('Train History')
    plt.ylabel('Train')
    plt.xlabel('Epoch')
    plt.legend(['train', 'validation'], loc='center right')
    plt.show()

show_train_history(train_history, 'accuracy', 'accuracy')
show_train_history(train_history, 'loss', 'loss')

# Confusion Matrix混淆矩陣
import pandas as pd
prediction = model.predict(test_data)
prediction_label=np.argmax(prediction,axis=1)
print(test_label.shape)
pd.crosstab(test_label_original, prediction_label, rownames=['label'], colnames=['predict'])
     
